{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with 'Python 3.12.7' requires the ipykernel package.\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: '/opt/homebrew/bin/python3.12 -m pip install ipykernel -U --user --force-reinstall'"
          ]
        }
      ],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with 'Python 3.12.7' requires the ipykernel package.\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: '/opt/homebrew/bin/python3.12 -m pip install ipykernel -U --user --force-reinstall'"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "import os\n",
        "\n",
        "project_root = os.path.abspath(os.path.join(os.getcwd(), '..', '..', '..'))\n",
        "sys.path.append(project_root)\n",
        "\n",
        "print(project_root)\n",
        "\n",
        "import machine_learning.files_lib as FL\n",
        "import machine_learning.ml_lib as ML\n",
        "from data_extractor.data_extractor import load_df, extract_X_y_from_df \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = load_df(\"../../../data/\")\n",
        "# Filter the data and add the column 'label' depends what you need\n",
        "df = df.query(\"desired_answer == answer and data_type in ['REAL', 'FAKE']\")\n",
        "df['label'] = df.apply(lambda x: 1 if x.block_no in [1,3] else 0, axis = 1)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X,y = extract_X_y_from_df(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "param_grid = {\n",
        "    'classifier__n_estimators': [ 200, 300 ],\n",
        "    'classifier__max_depth': [10, 20, 30],\n",
        "    'classifier__min_samples_split': [5, 10],\n",
        "    'classifier__max_features': ['sqrt'],\n",
        "    'classifier__bootstrap': [True, False],\n",
        "    'classifier__class_weight': [None, 'balanced']\n",
        "}\n",
        "\n",
        "result_folder = \"../results/random_forest/\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "best_model, best_params, test_score = ML.grid_search_random_forest_eeg_2(\n",
        "    X, y, param_grid, test_size=0.2, cv=5, scoring='accuracy'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import machine_learning.visualisation_lib as VL\n",
        "\n",
        "\n",
        "file_path = \"your_file_path.json\"\n",
        "cv_results_df, best_params, best_score, test_score, classification_report = FL.read_grid_search_results(file_path)\n",
        "\n",
        "print(\"Best Parameters:\")\n",
        "print(best_params)\n",
        "print(f\"\\nBest Cross-Validation Score: {best_score:.4f}\")\n",
        "print(f\"Test Score: {test_score:.4f}\\n\")\n",
        "\n",
        "VL.plot_mean_test_scores(cv_results_df, 'classifier__max_depth')\n",
        "VL.plot_mean_test_scores(cv_results_df, 'classifier__n_estimators')\n",
        "VL.plot_mean_test_scores(cv_results_df, 'classifier__min_samples_split')\n",
        "\n",
        "VL.plot_heatmap_mean_test_scores(cv_results_df, 'classifier__n_estimators', 'classifier__max_depth')\n",
        "\n",
        "# VL.plot_fit_and_score_times(cv_results_df, 'classifier__n_estimators')\n",
        "\n",
        "if classification_report:\n",
        "    print(\"Classification Report:\")\n",
        "    for label, metrics in classification_report.items():\n",
        "        if isinstance(metrics, dict):\n",
        "            if label in ['accuracy', 'macro avg', 'weighted avg']:\n",
        "                print(f\"\\n{label}:\")\n",
        "                for metric_name, metric_value in metrics.items():\n",
        "                    print(f\"  {metric_name}: {metric_value:.4f}\")\n",
        "            else:\n",
        "                print(f\"\\nClass {label}:\")\n",
        "                for metric_name, metric_value in metrics.items():\n",
        "                    print(f\"  {metric_name}: {metric_value:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "param_grid = {\n",
        "    'classifier__n_estimators': [ 200, 300 ],\n",
        "    'classifier__max_depth': [20, 30],\n",
        "    'classifier__min_samples_split': [2, 5],\n",
        "    'classifier__max_features': ['sqrt'],\n",
        "    'classifier__bootstrap': [True, False],\n",
        "    'classifier__class_weight': [None, 'balanced']\n",
        "}\n",
        "\n",
        "result_folder = \"../results/random_forest/\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "best_model, best_params, test_score = ML.grid_search_random_forest_eeg(\n",
        "    X, y, param_grid, test_size=0.2, cv=5, scoring='accuracy'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
